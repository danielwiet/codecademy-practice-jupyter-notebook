{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the emails you will be censoring. The open() function is opening the text file that the emails are contained in and the .read() method is allowing us to save their contexts to the following variables:\n",
    "email_one = open(\"email_one.txt\", \"r\").read()\n",
    "email_two = open(\"email_two.txt\", \"r\").read()\n",
    "email_three = open(\"email_three.txt\", \"r\").read()\n",
    "email_four = open(\"email_four.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning, Board of Investors,\n",
      "\n",
      "Progress is going great!\n",
      "\n",
      "We have made great strides in the last month improving the learning algorithms that the system has been using to acquire information. Now, the system is learning faster than ever and we are hard pressed to continue to find new information to feed it and sustain its growth.\n",
      "\n",
      "Soon, we'll expand the scope of the learning algorithms and connect the system with the internet. This will allow it to find and determine the information it needs to continue growing.\n",
      "\n",
      "Every month we come closer to achieving our goal of making the world a better place. Famine, plague, war, and poverty are all conquerable with the power of our system!\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(email_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe above code will do the same as the code below, but it will add a space between the two words. How \\ncan you automate a function to do this???\\n\\nYou will need to .split(' ') the phrase based on a space character (and store it in an empty list?)\\nYou will have to find the len() of each string\\nYou wil have to replace() the strings with a symbol with len(string)\\nyou will have to join() the symbolic version of the sting phrase\\nthen you have to append() the joined string symbology back into the email\\n\\nThinking through this, the steps above will not preserve the space between the strings...\\nmaybe iterate through the censed word by list slicing(because strings are lists)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all instances of 'learning algorithms' from the first email\n",
    "\n",
    "email_one_censored = email_one.replace('learning algorithms',\n",
    "                                       (len('learning') * '#' + ' ' +\n",
    "                                        len('algorithms') * '#'))\n",
    "\n",
    "'''\n",
    "The above code will do the same as the code below, but it will add a space between the two words. How \n",
    "can you automate a function to do this???\n",
    "\n",
    "You will need to .split(' ') the phrase based on a space character (and store it in an empty list?)\n",
    "You will have to find the len() of each string\n",
    "You wil have to replace() the strings with a symbol with len(string)\n",
    "you will have to join() the symbolic version of the sting phrase\n",
    "then you have to append() the joined string symbology back into the email\n",
    "\n",
    "Thinking through this, the steps above will not preserve the space between the strings...\n",
    "maybe iterate through the censed word by list slicing(because strings are lists)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-123ca0c5cb80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_censor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memail_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-123ca0c5cb80>\u001b[0m in \u001b[0;36mcensor\u001b[1;34m(terms, email)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#return replace_terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# returns the iteration above with a space between the indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_censor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memail_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "to_censor = ['learning', 'algorithms', 'information']\n",
    "def censor(terms, email):\n",
    "    #words = term.split()\n",
    "    #return words\n",
    "    # splits the term and saves it into list format\n",
    "    for n in range(len(terms)):\n",
    "    # this iterates by index value (0, 1, 2, etc.) treating a word as one unit\n",
    "        terms[n] =  \"\".join(['#' for n in range(len(terms[n]))])\n",
    "    #return terms\n",
    "        # for each word at index[n], it takes the string, counts the length, and replaces the values with '#'\n",
    "    replace_terms = \" \".join(terms)\n",
    "    #return replace_terms\n",
    "    # returns the iteration above with a space between the indices\n",
    "    return email.replace(terms.lower(), replace_term).replace(terms.upper(), replace_term).replace(terms.title(), replace_term)\n",
    "\n",
    "print(censor(to_censor, email_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning, Board of Investors,\n",
      "\n",
      "Progress is going great!\n",
      "\n",
      "We have made great strides in the last month improving the ################### that the system has been using to acquire information. Now, the system is learning faster than ever and we are hard pressed to continue to find new information to feed it and sustain its growth.\n",
      "\n",
      "Soon, we'll expand the scope of the ################### and connect the system with the internet. This will allow it to find and determine the information it needs to continue growing.\n",
      "\n",
      "Every month we come closer to achieving our goal of making the world a better place. Famine, plague, war, and poverty are all conquerable with the power of our system!\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def email_one_cen_func(word, email):\n",
    "    censed_word = ''\n",
    "    for item in word:\n",
    "        censed_word += '#'\n",
    "    return email.replace(word.lower(), censed_word).replace(word.upper(), censed_word).replace(word.title(), censed_word)\n",
    "\n",
    "print(email_one_cen_func('learning algorithms', email_one))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
